{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment = load_files('data/imdb1/', random_state=41)\n",
    "sentiment.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, test_data, train_target, test_target = train_test_split(sentiment.data, sentiment.target, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorized_train_data = vectorizer.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Binary Word Counts\n",
    "vectorizer1 = CountVectorizer(binary=True,lowercase=True)\n",
    "vectorized_train_data1 = vectorizer1.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Models\n",
    "clf = MultinomialNB()\n",
    "clf1 = MultinomialNB()\n",
    "#Fitting Models\n",
    "clf.fit(vectorized_train_data, train_target)\n",
    "clf1.fit(vectorized_train_data1, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.818\n",
      "0.826\n"
     ]
    }
   ],
   "source": [
    "#Scoring Models\n",
    "print 'Word Count Accuracy : {}'.format(clf.score(vectorizer.transform(test_data), test_target))\n",
    "print clf1.score(vectorizer1.transform(test_data), test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[205  50]\n",
      " [ 41 204]]\n",
      "[[207  48]\n",
      " [ 39 206]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print confusion_matrix(test_target, clf.predict(vectorizer.transform(test_data)))\n",
    "print confusion_matrix(test_target, clf1.predict(vectorizer1.transform(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.819047619048\n",
      "0.816143497758\n",
      "0.85\n",
      "0.782608695652\n",
      "0.835978835979\n",
      "0.78612716763\n",
      "0.817777777778\n",
      "0.788571428571\n",
      "0.78021978022\n",
      "0.820754716981\n"
     ]
    }
   ],
   "source": [
    "f1s = []\n",
    "kf = KFold(len(sentiment.data), n_folds=10)\n",
    "for train, test in kf:\n",
    "    train_fold = [sentiment.data[i] for i in train]\n",
    "    test_fold = [sentiment.data[i] for i in test]\n",
    "    vectorized_train_data = vectorizer.fit_transform(train_fold)\n",
    "    clf.fit(vectorized_train_data, sentiment.target[train])\n",
    "    y_pred = clf.predict(vectorizer.transform(test_fold))\n",
    "    f1 = f1_score(sentiment.target[test], y_pred)\n",
    "    print f1\n",
    "    f1s.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80972295196166522"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.819047619048\n",
      "0.821428571429\n",
      "0.847290640394\n",
      "0.778378378378\n",
      "0.789189189189\n",
      "0.78612716763\n",
      "0.826666666667\n",
      "0.784090909091\n",
      "0.780748663102\n",
      "0.816901408451\n"
     ]
    }
   ],
   "source": [
    "vectorizer2 = CountVectorizer(stop_words = 'english')\n",
    "clf2 = MultinomialNB()\n",
    "\n",
    "f1s2 = []\n",
    "for train, test in KFold(len(sentiment.data), n_folds=10):\n",
    "    train_fold = [sentiment.data[i] for i in train]\n",
    "    test_fold = [sentiment.data[i] for i in test]\n",
    "    vectorized_train_data = vectorizer2.fit_transform(train_fold)\n",
    "    clf2.fit(vectorized_train_data, sentiment.target[train])\n",
    "    y_pred = clf2.predict(vectorizer2.transform(test_fold))\n",
    "    f1 = f1_score(sentiment.target[test], y_pred)\n",
    "    print f1\n",
    "    f1s2.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80498692133777894"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(f1s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def negate_sequence(text):\n",
    "    negation = False\n",
    "    delims = \"?.,!:;\"\n",
    "    exp = re.compile(r\"(not\\b|no\\b|n't\\b)\")\n",
    "    result = []\n",
    "    words = text.split()\n",
    "    prev = None\n",
    "    pprev = None\n",
    "    for word in words:\n",
    "        stripped = word.strip(delims).lower()\n",
    "        negated = \"not_\" + stripped if negation else stripped\n",
    "        result.append(negated)\n",
    "\n",
    "#         if any(neg in word for neg in ):\n",
    "        if exp.match(word):\n",
    "            negation = not negation\n",
    "\n",
    "        if any(c in word for c in delims):\n",
    "            negation = False\n",
    "\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentiment = load_files('data/imdb1/', random_state=41)\n",
    "\n",
    "negated_sentiment = [negate_sequence(i) for i in sentiment.data]\n",
    "\n",
    "train_data, test_data, train_target, test_target = train_test_split(negated_sentiment, sentiment.target, random_state=41)\n",
    "vectorizer2 = CountVectorizer(binary=True,lowercase=True)\n",
    "vectorized_train_data2 = vectorizer2.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.844\n",
      "[[211  44]\n",
      " [ 34 211]]\n"
     ]
    }
   ],
   "source": [
    "clf2 = MultinomialNB()\n",
    "clf2.fit(vectorized_train_data2, train_target)\n",
    "print clf2.score(vectorizer2.transform(test_data), test_target)\n",
    "print confusion_matrix(test_target, clf2.predict(vectorizer2.transform(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.802\n",
      "[[222  33]\n",
      " [ 66 179]]\n"
     ]
    }
   ],
   "source": [
    "clf3 = BernoulliNB()\n",
    "vectorizer3 = CountVectorizer(binary=True,lowercase=True)\n",
    "vectorized_train_data3 = vectorizer3.fit_transform(train_data)\n",
    "clf3.fit(vectorized_train_data2, train_target)\n",
    "print clf3.score(vectorizer3.transform(test_data), test_target)\n",
    "print confusion_matrix(test_target, clf3.predict(vectorizer3.transform(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.798\n",
      "[[220  35]\n",
      " [ 66 179]]\n"
     ]
    }
   ],
   "source": [
    "clf4 = BernoulliNB()\n",
    "train_data, test_data, train_target, test_target = train_test_split(sentiment.data, sentiment.target, random_state=41)\n",
    "vectorizer4 = CountVectorizer(binary=True,lowercase=True)\n",
    "vectorized_train_data4 = vectorizer4.fit_transform(train_data)\n",
    "clf4.fit(vectorized_train_data4, train_target)\n",
    "print clf4.score(vectorizer4.transform(test_data), test_target)\n",
    "print confusion_matrix(test_target, clf4.predict(vectorizer4.transform(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
