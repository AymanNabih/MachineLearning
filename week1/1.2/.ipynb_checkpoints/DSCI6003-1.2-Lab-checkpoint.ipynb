#KNN Implementation

Write as python class that implements KNN algorithm. Include all you code in the file `KNearestNeighbors.py`.

### Data

For this exercise, we'll use Fisher's Iris Data Set:

```python
>>> from sklearn import datasets
>>> iris = datasets.load_iris()
```

Select 3 or 4 points from each class which you can use as test points. Use the rest of the data set for prediction.

###Exercise

__1__- Implement the function `euclidean_distance` which computes the Euclidean distance between two numpy arrays. Euclidean distance only works for continuous features.

__2__- Implement the class `KNearestNeighbors`. We are going to write our code similar to how sklearn does. So you should be able to run your code like this:

```python
knn = KNearestNeighbors(k=3, distance=euclidean_distance)
knn.fit(X, y)
y_predict = knn.predict(X)
```

Here `X` is the feature matrix as a 2d numpy array, `y` is the labels as a numpy array. 3 is the *k* and `euclidean_distance` is the distance function. `predict` will return a numpy array of the predicted labels.

You will need to implement a `KNearestNeighbors` class with three methods: `fit`, `predict` and `score` (calculates accuracy).

__3__ Implement `cosine_distance` which computes the cosine distance function. This gives the angle between the two vectors.

__4__- Plot the decision boundary. Look at this [sklearn example](http://scikit-learn.org/stable/auto_examples/neighbors/plot_classification.html#example-neighbors-plot-classification-py). Note that you'll need exactly 2 continuous features in order to do this.
