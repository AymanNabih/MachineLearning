{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6003 Assessment 2\n",
    "\n",
    "* Time: 60 minutes\n",
    "* Closed book\n",
    "* Individual\n",
    "\n",
    "There are 18 questions that cover these topics:\n",
    "\n",
    "* Logistic Regression\n",
    "* Model Evaluation\n",
    "* SVMs\n",
    "* Regularization\n",
    "* Decision Tree\n",
    "* Random Forest\n",
    "\n",
    "We recommend skimming over all the questions and solving the ones that you are most confident about first.\n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessment\n",
    "\n",
    "1) You fit a linear regression to predict SAT score with many predictors, one of which is whether or not the student was homeschooled. `Beta_homeschool = -40`. How do you interpret the coefficient?    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> All else being equal, a homeschooled student has a 40 point lower SAT score than a non-homeschooled student."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) You fit a logistic regression to predict whether or not a student was admitted to a 4-year university. Again, `Beta_homeschool = -0.3`. How do you interpret the coefficient?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We calculate the odds to get `e^-0.3 = 0.74`. So, all else being equal, a homeschooled student's odds of getting admitted is 74% that of a non-homeschooled student."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) In the following image, label the decision boundary of the SVM(and explain why you chose it).\n",
    "\n",
    "![](../assessment2/images/margin.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Its the red line! An SVM is a Maximum margin classifier and as such it tries to maximize the margin in its optimization.  To do this, the distance to each of the support vectors must be equal (the light grey lines above) and maximal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Give an example of a confusion matrix with precision > 90% and recall < 10% consisting of nonzero entries.\n",
    "\n",
    "$$precision = \\frac{TP}{TP + FP}$$\n",
    "$$recall = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "Orient your confusion matrix like this:\n",
    "\n",
    "```\n",
    "         Predicted\n",
    "         ---------\n",
    "        | TP | FN |\n",
    "Actual   ---------\n",
    "        | FP | TN |\n",
    "         ---------\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *There could be any number of answers. One possible confusion matrix is:*\n",
    ">\n",
    ">```\n",
    ">         Predicted\n",
    ">         ---------\n",
    ">        | 10 | 91 |\n",
    ">Actual   ---------\n",
    ">        | 01 | 99 |\n",
    ">         ---------\n",
    ">```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Give an example of a confusion matrix with accuracy > 90%, but both precision < 10% and recall < 10%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *There could be any number of answers. One possible confusion matrix is:*\n",
    ">\n",
    ">```\n",
    ">         Predicted\n",
    ">         ------------\n",
    ">        | 04 |   91  |\n",
    ">Actual   ------------\n",
    ">        | 91 | 10000 |\n",
    ">         ------------\n",
    ">```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) What are 2 benefits of using F_1 score during model selection/hyper-parameter tuning, versus say using **accuracy** or a **confusion matrix**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> F_1 is a point estimate and as such it can be effectively used to choose from many possible models (or values of hyperparameter) by comparing the point estimates in a semi-automated fashion (advantage over confusion matrix). Also it tries to capture the trade off between precision and recall in this single point estimate (improvement over accuracy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Say I'm building a Decision Tree Classifier on this dataset.\n",
    "\n",
    "    | color | number | label |\n",
    "    | ----- | ------ | ----- |\n",
    "    | blue  | 1      | 0     |\n",
    "    | blue  | 2      | 1     |\n",
    "    | red   | 1      | 0     |\n",
    "    | red   | 5      | 1     |\n",
    "\n",
    "Splitting on what feature and value has the best information gain? Use your intuition rather than calculating all the entropy values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Splitting on number for (<= 1) or (> 1) gives the best information gain because the resulting leaves are pure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Say I'm building a Decision Tree Regressor. What is the information gain of this split of the data?\n",
    "\n",
    "To calculate information gain, you only need the values of the label, so those are the values given. You are not given the feature values.\n",
    "\n",
    "```\n",
    "Split 1: 6, 5, 8, 8\n",
    "Split 2: 5, 4, 2, 4, 4\n",
    "```\n",
    "\n",
    "Hint: Use variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">*Use the information gain formula with variance as the measure of disorder (instead of entropy).*\n",
    ">\n",
    ">    ```\n",
    ">    Var(S) = Var(6,5,8,8,5,4,2,4,4) = 3.4321\n",
    ">    Var(A) = Var(6,5,8,8) = 1.6875\n",
    ">    Var(B) = Var(5,4,2,4,4) = 0.9600\n",
    ">\n",
    ">    Gain = Var(S) - 4/9 * Var(A) - 5/9 * Var(B)\n",
    ">         = 2.1488\n",
    ">    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) You build a Decision Tree and get these stats:\n",
    "\n",
    "```\n",
    "train set accuracy:  90%\n",
    "train set precision: 92%\n",
    "train set recall:    87%\n",
    "\n",
    "test set accuracy:   60%\n",
    "test set precision:  65%\n",
    "test set recall:     52%\n",
    "```\n",
    "\n",
    "What's going on? What tactic(s) do we have to modify our Decision Tree to fix the issue?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Overfitting is happening. One method to modify the tree is to prune it.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10) How are the Decision Trees in Random Forests different from standard Decision Trees?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *In Random Forests, the trees are built on bootstrapped samples, so you will very likely have duplicates in your data.*\n",
    "    \n",
    "> *In the Decision Trees in Random Forests, at each node, we randomly select the available features to split on. In standard Decision Trees, we consider all the features.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11) Why are we able to cross validate our Random Forest with our training set (OOB error)? I.e. Why doesn't this count as testing on my training set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *The bootstapping means that we are sampling with replacement, so roughly 63% of the data is included in building each tree in the random forest. The 37% that's left out can be used as a test set.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12) Label the following trace plot curves (dotted or solid) and explain your reasoning for each.\n",
    "\n",
    "![](../assessment2/images/octopus.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ![](../assessment2/images/octopus_sol.png)\n",
    "\n",
    "> LASSO drives the coefficients to zero much quicker than Elastic-Net. Elastic-Net is something of an inbetween of Ridge and LASSO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13) Name the tuning parameters for the following algorithms and describe what you'd expect to happen with bias and variance as you increase the tuning parameter. For the SVM classifier also describe how the decision boundary/margin changes as its hyperparameters change.\n",
    "\n",
    "    * Lasso / Ridge\n",
    "    * SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *In Lasso and Ridge, you tune alpha (or lambda), which increases the penalty for your beta coefficients, which decreases variance and increases bias.*\n",
    "    \n",
    "> *In SVMs, you tune the soft-margin constant C which is the penalty assigned to margin errors. Increasing C, decreases the margin which tends to increase variance and decrease bias. Decreasing C has the opposite effect.*\n",
    "    \n",
    "> *Note that the SVM cost parameter is different from sklearn's parameter `c`.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14) Label each of the following Lp space plots (with either Ridge, LASSO, or Elastic-Net) and explain your reasoning for each.\n",
    "\n",
    "![](../assessment2/images/lp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The left one is LASSO (L1), the right one is Ridge (L2). L1 norm enforces sparsity due to the diamond shape of the level curve in Lp space.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15) A logistic regression is fit to model whether or not a woman has an affair!  Interpret the coefficients for 'yrs_married'.  Observe the column of p-values, one for each predictor, and comment on any next steps you might take (more than 1 answer!).\n",
    "\n",
    "![Logistic Regression Output](../assessment2/images/q2_logstic_regression.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. We calculate the odds to get e^0.11 = 1.1163. So, all else being equal, a 1 year increase in years of marriage increases the odds of having an affair by a multiplicative factor of 1.1163.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16) What does it mean for an SVM to be a `maximum margin` classifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Rather than directly optimizing over a hypothesis function (and cost) we are optimizing the margin between the decision boundary and support vectors.  This has the effect of creating a more generalized decision function/boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17) You have a bag full of marbles:  501 blue and 530 red to be exact.  \n",
    "\n",
    "$$I_{G}(f) = \\sum_{i=1}^{m} f_{i}(1 - f_{i})$$\n",
    "\n",
    "a. What is the Gini impurity of your bag of marbles?\n",
    "\n",
    "b. You split your bag of marbles into two bags!  Bag1 has 1 blue and 30 Red.  Bag2 has 500 blue and 500 red.  What is the Gini impurity of Bag1 and Bag 2?  What is the Information Gain in going from Bag --> Bag1 and Bag2?\n",
    "\n",
    "c. Consider a different split where Bag1 has 100 blue and 400 red, and Bag2 has 401 blue and 130 red.  \n",
    "Again, use Gini impurity to compute the Information Gain.\n",
    "\n",
    "d. Why is the gain much better in part (c), despite the purity of Bag1 in part (b)?  \n",
    "\n",
    "e. In the general classification tree context, for any given node, how is a particular split chosen?  \n",
    "\n",
    "![Marbles](../assessment2/images/q4_marbles.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> a. and b.\n",
    ">\n",
    ">|      | Blue | Red | p_Blue | p_Red | Gini_Coefficient |\n",
    ">| -----| -----| -----| -----| -----| -----| \n",
    ">|     Bag | 501 | 530 | 0.49 | 0.51 | 0.500 |\n",
    ">|     Bag1  | 1 |  30 | 0.03 | 0.97 | 0.062 |\n",
    ">|     Bag2   | 500 | 500 | 0.50 | 0.50 | 0.500 |\n",
    ">\n",
    ">Information Gain going from Bag --> Bag1 and Bag2:\n",
    ">0.500 - [(31/1031)*0.062 + (1000/1031)*0.500] = 0.013\n",
    ">\n",
    ">c.\n",
    ">\n",
    ">\n",
    ">|      | Blue | Red | p_Blue | p_Red | Gini_Coefficient |\n",
    ">| -----| -----| -----| -----| -----| -----| \n",
    ">|     Bag | 501 | 530 | 0.49 | 0.51 | 0.500 |\n",
    ">|     Bag1  | 100 |  400 | 0.20 | 0.80 | 0.320 |\n",
    ">|     Bag2   | 401 | 130 | 0.76 | 0.24 | 0.370 |\n",
    ">\n",
    ">Information Gain going from Bag --> Bag1 and Bag2:\n",
    ">0.500 - [(500/1031) * 0.320 + (531/1031) * 0.370] = 0.154\n",
    ">\n",
    "d.  Bag1 in part (b) only has 31 marbles.  Splits that create purity in one node but don't have much n-size don't help us           with the classification very much, which is reflected in the weights in the information gain computation.  \n",
    ">\n",
    ">e.  Consider all predictors and all possible split points, then choose the predictor-split combination with greatest >            information gain.  \n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18) Write a one sentence description of `precision` in plain English.  Do the same for `recall`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "> Precision is how many selected items are relevant.  Recall is how many relevant items are selected."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
